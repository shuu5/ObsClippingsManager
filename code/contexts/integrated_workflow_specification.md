# çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä»•æ§˜æ›¸

## æ¦‚è¦
- **è²¬å‹™**: å…¨å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å˜ä¸€ã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œã™ã‚‹çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
- **ä¾å­˜**: yaml_template_manager â†’ å…±æœ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« â†’ å€‹åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- **å®Ÿè¡Œ**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ï¼ˆAIæ©Ÿèƒ½å«ã‚€ï¼‰

## å‡¦ç†ãƒ•ãƒ­ãƒ¼å›³
```mermaid
flowchart TD
    A["å…¥åŠ›ãƒ‡ãƒ¼ã‚¿"] --> B["çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹"]
    B --> C["è¨­å®šãƒ»ãƒ‘ã‚¹è§£æ±º"]
    C --> D["yaml_template_manageråˆæœŸåŒ–"]
    D --> E["ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œå‡º"]
    E --> F["å‡¦ç†å¯¾è±¡è«–æ–‡æ±ºå®š"]
    F --> G["åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"]
    G --> H["AIæ©Ÿèƒ½æœ‰åŠ¹æ€§ç¢ºèª"]
    H -->|æœ‰åŠ¹| I["AIæ©Ÿèƒ½å®Ÿè¡Œ"]
    H -->|ç„¡åŠ¹| J["æœ€çµ‚åŒæœŸ"]
    I --> J
    J --> K["çµæœå‡ºåŠ›"]
    K --> L["å®Œäº†"]
    
    D -->|YAMLä¸æ­£| M["YAMLä¿®å¾©å‡¦ç†"]
    G -->|ã‚¨ãƒ©ãƒ¼| N["ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"]
    I -->|APIåˆ¶é™| O["ãƒ¬ãƒ¼ãƒˆåˆ¶é™å‡¦ç†"]
    M --> E
    N --> P["ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"]
    O --> I
```

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–¢ä¿‚å›³
```mermaid
graph LR
        A["çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"] --> B["yaml_template_manager"]
    A --> C["åŸºæœ¬æ©Ÿèƒ½"]
    A --> D["CitationFetcher"]
    A --> E["AIå¼•ç”¨è§£æ"]
    A --> F["ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²"]
    A --> G["AIã‚¿ã‚°ä»˜ã‘"]
    A --> H["è¦ç´„ç¿»è¨³"]
    A --> I["è½åˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"]
    A --> J["çŠ¶æ…‹ç®¡ç†"]
    
    B --> C
    B --> D
    B --> E
    B --> F
    B --> G
    B --> H
    B --> I
    B --> J
    
    K["è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"] -.-> A
    L["ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ "] -.-> A
    M["ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ "] -.-> A
    N["Claude API"] -.-> A
    O["CrossRef API"] -.-> D
    P["Semantic Scholar API"] -.-> D
    Q["OpenCitations API"] -.-> D
```

## YAMLãƒ˜ãƒƒãƒ€ãƒ¼å½¢å¼

### å…¥åŠ›ï¼ˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
```yaml
---
# === ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹è¨­å®š ===
workspace_configuration:
  workspace_path: "/home/user/ManuscriptsManager"
  bibtex_file: "CurrentManuscript.bib"
  clippings_dir: "Clippings"
  output_dir: "Clippings"

# === å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===
execution_parameters:
  force_reprocess: false
  disable_ai_features: false
  target_papers: null
  show_plan: false
  dry_run: false
  
# === ã‚·ã‚¹ãƒ†ãƒ æƒ…å ± ===
system_info:
  workflow_version: '3.2'
  execution_mode: 'integrated'
  start_time: '2025-01-15T12:00:00.123456+00:00'
---
```

### å‡ºåŠ›ï¼ˆçµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœï¼‰
```yaml
---
# === ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆå®Ÿè¡Œæ™‚ç¢ºå®šï¼‰ ===
workspace_configuration:
  workspace_path: "/home/user/ManuscriptsManager"
  bibtex_file: "CurrentManuscript.bib"
  clippings_dir: "Clippings"
  output_dir: "Clippings"
  resolved_paths:
    bibtex_absolute: "/home/user/ManuscriptsManager/CurrentManuscript.bib"
    clippings_absolute: "/home/user/ManuscriptsManager/Clippings"

# === å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç¢ºå®šå€¤ï¼‰ ===
execution_parameters:
  force_reprocess: false
  disable_ai_features: false
  target_papers: ["smith2023test", "jones2022biomarkers", "davis2023neural"]
  show_plan: false
  dry_run: false

# === ã‚·ã‚¹ãƒ†ãƒ æƒ…å ± ===
system_info:
  workflow_version: '3.2'
  execution_mode: 'integrated'
  start_time: '2025-01-15T12:00:00.123456+00:00'
  end_time: '2025-01-15T12:03:00.654321+00:00'

# === å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼ï¼ˆçµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å°‚ç”¨ï¼‰ ===
integrated_execution_summary:
  executed_at: '2025-01-15T12:00:00.123456'
  total_papers_processed: 3
  total_execution_time: 180.5
  overall_status: 'completed'
  
  steps_executed:
    - organize
    - sync
    - fetch
    - section_parsing
    - ai_citation_support
    - tagger
    - translate_abstract
    - ochiai_format
    - final_sync
    
  steps_summary:
    organize:
      status: completed
      papers_processed: 3
      execution_time: 15.2
      files_reorganized: 3
    sync:
      status: completed
      papers_processed: 3
      execution_time: 8.1
      sync_operations: 6
    fetch:
      status: completed
      papers_processed: 3
      execution_time: 18.7
      dois_extracted: 12
      references_bib_files_created: 3
      crossref_success: 8
      semantic_scholar_success: 3
      opencitations_success: 1
      fallback_placeholders: 0
      average_quality_score: 0.89
    ai_citation_support:
      status: completed
      papers_processed: 3
      execution_time: 25.3
      citations_processed: 8
    tagger:
      status: completed
      papers_processed: 3
      execution_time: 42.7
      ai_requests: 3
      tags_generated: 45
    translate_abstract:
      status: completed
      papers_processed: 3
      execution_time: 38.9
      ai_requests: 3
      translations_generated: 3
    ochiai_format:
      status: completed
      papers_processed: 3
      execution_time: 51.3
      ai_requests: 3
      summaries_generated: 3
    final_sync:
      status: completed
      papers_processed: 3
      execution_time: 12.0
      final_validations: 3

# === ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†çµæœ ===
edge_cases_handling:
  detected_issues:
    missing_in_clippings: 2
    orphaned_in_clippings: 1
    yaml_repair_needed: 0
  resolution_actions:
    files_created: 2
    files_moved: 0
    headers_repaired: 0
  post_resolution_status: 'resolved'

# === ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šè¨˜éŒ² ===
execution_log:
  errors: []
  warnings: 
    - "smith2023test: Abstract section shorter than expected"
  performance_metrics:
    peak_memory_usage: "45.2 MB"
    api_requests_total: 9
    api_rate_limit_hits: 0

# === ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ± ===
backup_summary:
  backups_created: 6
  backup_location: "backups/integrated_20250115_120000/"
  total_backup_size: "2.3 MB"
  recovery_points_available: true
---
```

## å®Ÿè£…
```python
class IntegratedWorkflow:
    def __init__(self, config_manager, logger):
        self.config_manager = config_manager
        self.logger = logger.get_logger('IntegratedWorkflow')
        
        # YAML Template Manager
        self.template_manager = YAMLTemplateManager(config_manager, logger)
        
        # çŠ¶æ…‹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.status_manager = StatusManager(config_manager, logger)
        
        # å„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        self.organize_workflow = OrganizeWorkflow(config_manager, logger)
        self.sync_workflow = SyncWorkflow(config_manager, logger)
        self.fetch_workflow = FetchWorkflow(config_manager, logger)
        self.section_parsing_workflow = SectionParsingWorkflow(config_manager, logger)
        self.ai_citation_support_workflow = AICitationSupportWorkflow(config_manager, logger)
        self.tagger_workflow = TaggerWorkflow(config_manager, logger)
        self.translate_workflow = TranslateAbstractWorkflow(config_manager, logger)
        self.ochiai_workflow = OchiaiFormatWorkflow(config_manager, logger)
        
    def execute_integrated_workflow(self, force_reprocess=False, disable_ai_features=False, 
                                  target_papers=None, show_plan=False):
        """çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œ"""
        start_time = time.time()
        execution_results = {
            'status': 'running',
            'executed_steps': [],
            'skipped_steps': [],
            'failed_steps': [],
            'total_papers_processed': 0,
            'execution_time': 0,
            'edge_cases': {}
        }
        
        try:
            # 1. è¨­å®šã¨ãƒ‘ã‚¹ã®è§£æ±º
            workspace_path = self.config_manager.get_workspace_path()
            bibtex_file = self.config_manager.get_bibtex_file()
            clippings_dir = self.config_manager.get_clippings_dir()
            
            # 2. ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œå‡ºã¨å‡¦ç†å¯¾è±¡è«–æ–‡æ±ºå®š
            valid_papers, edge_cases = self._detect_edge_cases_and_get_valid_papers(
                bibtex_file, clippings_dir
            )
            execution_results['edge_cases'] = edge_cases
            execution_results['total_papers_processed'] = len(valid_papers)
            
            if show_plan:
                self._show_execution_plan(valid_papers, disable_ai_features)
                return execution_results
            
            # 3. é †æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
            workflow_steps = [
                ('organize', self.organize_workflow),
                ('sync', self.sync_workflow),
                ('fetch', self.fetch_workflow),
                ('section_parsing', self.section_parsing_workflow),
                ('ai_citation_support', self.ai_citation_support_workflow),
            ]
            
            # AIæ©Ÿèƒ½ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
            if not disable_ai_features:
                ai_steps = [
                    ('tagger', self.tagger_workflow),
                    ('translate_abstract', self.translate_workflow),
                    ('ochiai_format', self.ochiai_workflow),
                ]
                workflow_steps.extend(ai_steps)
            
            # æœ€çµ‚åŒæœŸ
            workflow_steps.append(('final-sync', self.sync_workflow))
            
            # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œ
            for step_name, workflow in workflow_steps:
                step_start_time = time.time()
                
                try:
                    # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
                    if self.config_manager.get('integrated_workflow.backup_strategy.create_checkpoint_backups', True):
                        self._create_checkpoint_backup(clippings_dir, step_name)
                    
                    self.logger.info(f"Starting step: {step_name}")
                    workflow.process_items(clippings_dir, valid_papers)
                    
                    step_execution_time = time.time() - step_start_time
                    execution_results['executed_steps'].append({
                        'name': step_name,
                        'status': 'completed',
                        'execution_time': step_execution_time
                    })
                    
                except (ProcessingError, APIError, ValidationError) as e:
                    # æ—¢çŸ¥ã®ã‚¨ãƒ©ãƒ¼ï¼šæ¨™æº–çš„ãªå‡¦ç†
                    self.logger.error(f"Step {step_name} failed with known error: {e}")
                    
                    # å¤±æ•—æ™‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
                    if self.config_manager.get('integrated_workflow.error_handling.auto_backup_on_failure', True):
                        self._create_failure_backup(clippings_dir, step_name, str(e))
                    
                    execution_results['failed_steps'].append({
                        'name': step_name,
                        'error': str(e),
                        'error_type': type(e).__name__,
                        'error_code': getattr(e, 'error_code', None)
                    })
                    
                    # é‡è¦ã§ãªã„ã‚¨ãƒ©ãƒ¼ã¯ç¶™ç¶šã€é‡è¦ãªã‚¨ãƒ©ãƒ¼ã¯ä¸­æ–­
                    if isinstance(e, (APIError, ConfigurationError)):
                        break  # é‡è¦ãªã‚¨ãƒ©ãƒ¼ã§ä¸­æ–­
                    
                except Exception as e:
                    # æœªçŸ¥ã®ã‚¨ãƒ©ãƒ¼ï¼šæ¨™æº–ä¾‹å¤–ã«å¤‰æ›
                    error = ProcessingError(
                        f"Unexpected error in step {step_name}: {str(e)}",
                        error_code="UNEXPECTED_STEP_ERROR",
                        context={"step": step_name, "execution_time": time.time() - step_start_time}
                    )
                    self.logger.error(f"Step {step_name} failed with unexpected error: {error}")
                    
                    execution_results['failed_steps'].append({
                        'name': step_name,
                        'error': str(error),
                        'error_type': 'ProcessingError',
                        'error_code': error.error_code
                    })
                    break
            
            execution_results['status'] = 'completed'
            
        except Exception as e:
            self.logger.error(f"Integrated workflow failed: {e}")
            execution_results['status'] = 'failed'
            execution_results['error'] = str(e)
        
        finally:
            execution_results['execution_time'] = time.time() - start_time
            
        return execution_results
    
    def _detect_edge_cases_and_get_valid_papers(self, bibtex_file, clippings_dir):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œå‡ºã¨æœ‰åŠ¹è«–æ–‡ãƒªã‚¹ãƒˆå–å¾—"""
        # BibTeXã‚¨ãƒ³ãƒˆãƒªãƒ¼å–å¾—
        bibtex_entries = self.bibtex_parser.parse_file(bibtex_file)
        bibtex_keys = set(bibtex_entries.keys())
        
        # Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è«–æ–‡å–å¾—
        clippings_keys = set()
        for md_file in glob.glob(os.path.join(clippings_dir, "**/*.md"), recursive=True):
            citation_key = self._extract_citation_key_from_path(md_file)
            if citation_key:
                clippings_keys.add(citation_key)
        
        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œå‡º
        missing_in_clippings = bibtex_keys - clippings_keys
        orphaned_in_clippings = clippings_keys - bibtex_keys
        valid_papers = bibtex_keys.intersection(clippings_keys)
        
        edge_cases = {
            'missing_in_clippings': list(missing_in_clippings),
            'orphaned_in_clippings': list(orphaned_in_clippings)
        }
        
        return list(valid_papers), edge_cases
```

## è¨­å®š
```yaml
integrated_workflow:
  enabled: true
  default_ai_features: true
  auto_edge_case_detection: true
  parallel_processing: false
  execution_timeout: 3600
  step_timeout: 600
  error_handling:
    auto_backup_on_failure: true
    retry_failed_steps: true
    max_retry_attempts: 3
    rollback_on_critical_failure: true
  backup_strategy:
    create_checkpoint_backups: true
    backup_frequency: "before_each_step"
    keep_execution_logs: true
```

## åŸºæœ¬åŸç†

### å˜ä¸€ã‚³ãƒãƒ³ãƒ‰çµ±åˆ
- **ã™ã¹ã¦ã®æ©Ÿèƒ½**ã‚’`run-integrated`ã«é›†ç´„
- **å¼•æ•°ãªã—å®Ÿè¡Œ**ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œï¼ˆAIæ©Ÿèƒ½å«ã‚€ï¼‰
- **å€‹åˆ¥è¨­å®š**ã¯å¿…è¦æ™‚ã®ã¿
- **AIç†è§£æ”¯æ´**ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹åŒ–

### çŠ¶æ…‹ç®¡ç†ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
- **YAMLãƒ˜ãƒƒãƒ€ãƒ¼**ã«ã‚ˆã‚‹å‡¦ç†çŠ¶æ…‹è¿½è·¡
- **è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—**ã§å®Œäº†æ¸ˆã¿å‡¦ç†ã‚’å›é¿
- **å¤±æ•—å†å®Ÿè¡Œ**ã§å¿…è¦ãªå‡¦ç†ã®ã¿å®Ÿæ–½
- **AIæ©Ÿèƒ½å‡¦ç†çŠ¶æ…‹**ã®è©³ç´°è¿½è·¡

### çµ±ä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
- **workspace_path**ä¸€ã¤ã§ã®å…¨ãƒ‘ã‚¹ç®¡ç†
- **è‡ªå‹•å°å‡º**ã«ã‚ˆã‚‹è¨­å®šã‚·ãƒ³ãƒ—ãƒ«åŒ–
- **å€‹åˆ¥æŒ‡å®š**ã§ã®æŸ”è»Ÿæ€§ç¢ºä¿

## ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### å‡¦ç†ãƒ•ãƒ­ãƒ¼
```
organize â†’ sync â†’ fetch â†’ section_parsing â†’ ai_citation_support â†’ enhanced-tagger â†’ enhanced-translate â†’ ochiai-format â†’ final-sync
```

### ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è‡ªå‹•è£œå®Œã‚·ã‚¹ãƒ†ãƒ 
- **fetchã‚¹ãƒ†ãƒƒãƒ—**: è«–æ–‡å†…ã®DOIæƒ…å ±ã‚’æŠ½å‡ºã—ã€å„è«–æ–‡ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`references.bib`ã‚’ç”Ÿæˆ
- **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥**: CrossRef â†’ Semantic Scholar â†’ OpenCitations
- **BibTeXå½¢å¼ä¿å­˜**: å–å¾—ã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’BibTeXå½¢å¼ã§ä¿å­˜
- **ai_citation_supportã‚¹ãƒ†ãƒƒãƒ—**: `references.bib`ã®å†…å®¹ã‚’YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã«çµ±åˆ

### ä¾å­˜é–¢ä¿‚
- å„ã‚¹ãƒ†ãƒƒãƒ—ã¯**é †æ¬¡å®Ÿè¡Œ**
- **å‰æ®µéšå®Œäº†**å¾Œã«æ¬¡æ®µéšå®Ÿè¡Œ
- **å¤±æ•—æ™‚ã¯å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—åœæ­¢**
- **AIæ©Ÿèƒ½**ã¯**ai-citation-supportå®Œäº†å¾Œ**ã«å®Ÿè¡Œ

### çŠ¶æ…‹è¿½è·¡
- å„è«–æ–‡ã®`.md`ãƒ•ã‚¡ã‚¤ãƒ«YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã§çŠ¶æ…‹ç®¡ç†
- ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å‡¦ç†çŠ¶æ…‹ã‚’è¨˜éŒ²
- å®Œäº†/å¤±æ•—/ä¿ç•™ã®çŠ¶æ…‹ç®¡ç†
- **AIæ©Ÿèƒ½å‡¦ç†çŠ¶æ…‹**ã®è¿½è·¡

## è¨­å®šã‚·ã‚¹ãƒ†ãƒ 

### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
```yaml
# config/config.yaml
workspace_path: "/home/user/ManuscriptsManager"

# è‡ªå‹•å°å‡ºãƒ‘ã‚¹
bibtex_file: "{workspace_path}/CurrentManuscript.bib"
clippings_dir: "{workspace_path}/Clippings"
output_dir: "{workspace_path}/Clippings"

# AIæ©Ÿèƒ½è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹ï¼‰
ai_generation:
  default_model: "claude-3-5-haiku-20241022"
  tagger:
    enabled: true
    batch_size: 8
  translate_abstract:
    enabled: true
    batch_size: 5
  ochiai_format:
    enabled: true
    batch_size: 3
  section_parsing:
    enabled: true
```

### è¨­å®šå„ªå…ˆé †ä½
1. **ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°** (æœ€é«˜å„ªå…ˆåº¦)
2. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«** (config.yaml)
3. **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤** (æœ€ä½å„ªå…ˆåº¦)

## IntegratedWorkflow ã‚¯ãƒ©ã‚¹

### ã‚¯ãƒ©ã‚¹è¨­è¨ˆæ¦‚è¦
çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ã—ã€é †æ¬¡å®Ÿè¡Œã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚

### ä¸»è¦å‡¦ç†ãƒ•ãƒ­ãƒ¼
1. **ãƒ‘ã‚¹è§£æ±º**: workspace_pathã‹ã‚‰å…¨ãƒ‘ã‚¹è‡ªå‹•å°å‡º
2. **è¨­å®šæ¤œè¨¼**: ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æ¤œå‡º
3. **å‡¦ç†å¯¾è±¡æ±ºå®š**: CurrentManuscript.bibã¨Clippings/*.mdã®DOIãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹å‡¦ç†å¯¾è±¡æ±ºå®š
4. **ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ**: é †æ¬¡å‡¦ç†ï¼ˆå‰æ®µéšå®Œäº†å¾Œã«æ¬¡æ®µéšï¼‰
5. **çŠ¶æ…‹æ›´æ–°**: å„ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†æ™‚ã®çŠ¶æ…‹è¨˜éŒ²

## organizeæ©Ÿèƒ½

### æ¦‚è¦
ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†æ©Ÿèƒ½ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€å°‚ç”¨ä»•æ§˜æ›¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼š
**[FileOrganizerä»•æ§˜æ›¸](file_organizer_specification.md)**

### ä¸»è¦æ©Ÿèƒ½
- CurrentManuscript.bibã¨Clippings/*.mdã®DOIãƒãƒƒãƒãƒ³ã‚°
- citation_keyãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã¸ã®æ•´ç†
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†ï¼ˆãƒãƒƒãƒã—ãªã„è«–æ–‡ã®ã‚¹ã‚­ãƒƒãƒ—ï¼‰
- YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã®è‡ªå‹•æ›´æ–°

## ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†ä»•æ§˜

### æ¦‚è¦
CurrentManuscript.bibã¨Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé–“ã®ä¸æ•´åˆã‚±ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹å‡¦ç†æ–¹é‡ã‚’å®šç¾©ã—ã¾ã™ã€‚

### ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®šç¾©

#### 1. missing_in_clippings
- **å®šç¾©**: CurrentManuscript.bibã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒClippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å¯¾å¿œã™ã‚‹DOIã‚’æŒã¤.mdãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„è«–æ–‡
- **å‡¦ç†æ–¹é‡**: **DOIæƒ…å ±è¡¨ç¤ºã®ã¿ã€å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—**
- **ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«**: WARNING
- **è¡¨ç¤ºå†…å®¹**: Citation keyã€DOIã€ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªDOIãƒªãƒ³ã‚¯

#### 2. orphaned_in_clippings  
- **å®šç¾©**: Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹ãŒCurrentManuscript.bibã«å¯¾å¿œã™ã‚‹DOIãŒè¨˜è¼‰ã•ã‚Œã¦ã„ãªã„.mdãƒ•ã‚¡ã‚¤ãƒ«
- **å‡¦ç†æ–¹é‡**: **è«–æ–‡æƒ…å ±è¡¨ç¤ºã®ã¿ã€å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—**
- **ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«**: WARNING  
- **è¡¨ç¤ºå†…å®¹**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€DOIï¼ˆYAMLãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ï¼‰

#### 3. no_doi_in_markdown
- **å®šç¾©**: Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«DOIæƒ…å ±ãŒå­˜åœ¨ã—ãªã„
- **å‡¦ç†æ–¹é‡**: **ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤ºã®ã¿ã€å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—**
- **ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«**: WARNING
- **è¡¨ç¤ºå†…å®¹**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€DOIä¸è¶³ã®è­¦å‘Š

### å‡¦ç†å¯¾è±¡è«–æ–‡ã®æ±ºå®š
ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’é™¤å¤–ã—ãŸå‡¦ç†å¯¾è±¡è«–æ–‡ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

### å®Ÿè¡Œçµæœã¸ã®å½±éŸ¿
```python
execution_results = {
    'status': 'success',
    'executed_steps': [],
    'skipped_steps': [],
    'failed_steps': [],
    'total_papers_processed': 0,
    'skipped_papers': {
        'missing_in_clippings': [],
        'orphaned_in_clippings': []
    },
    'execution_time': 0
}
```

### è¡¨ç¤ºä¾‹
```
ğŸ“Š Execution Summary:
Total papers in BibTeX: 15
Total markdown files: 12
Valid papers (both sources): 10
Skipped papers: 5
  - Missing markdown files: 3
  - Orphaned markdown files: 2

âš ï¸  Edge Cases Detected:
Missing markdown files for:
  - smith2023biomarkers (DOI: 10.1038/s41591-023-1234-5)
  - jones2024neural (DOI: 10.1126/science.xyz789)

Orphaned markdown files:
  - old_paper2022/old_paper2022.md
  - test_paper2021/test_paper2021.md
```

## è¨­è¨ˆåŸå‰‡

### ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†ã®åŸå‰‡
1. **å®‰å…¨æ€§å„ªå…ˆ**: ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†ã¯è¡Œã‚ãªã„
2. **æƒ…å ±æä¾›**: å•é¡Œã®è©³ç´°ã‚’æ˜ç¢ºã«å ±å‘Š
3. **å‡¦ç†ç¶™ç¶š**: ä¸€éƒ¨ã®å•é¡Œã§å…¨ä½“ãŒåœæ­¢ã—ãªã„
4. **ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£**: DOIãƒªãƒ³ã‚¯ç­‰ã§å•é¡Œè§£æ±ºã‚’æ”¯æ´

### æƒ…å ±æä¾›ã®å……å®Ÿ
1. **DOIè¡¨ç¤º**: è«–æ–‡ç‰¹å®šãƒ»å–å¾—æ”¯æ´ã®ãŸã‚
2. **ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãƒªãƒ³ã‚¯**: ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹æ”¯æ´
3. **æ˜ç¢ºãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: å•é¡Œã®æ€§è³ªã¨å¯¾å¿œæ–¹æ³•ã®æ˜ç¤º
4. **çµ±è¨ˆæƒ…å ±**: å…¨ä½“çš„ãªå‡¦ç†çŠ¶æ³ã®æŠŠæ¡æ”¯æ´

## ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ä»•æ§˜

### åŸºæœ¬å®Ÿè¡Œ
```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè¡Œï¼ˆæ¨å¥¨ãƒ»AIæ©Ÿèƒ½å«ã‚€ï¼‰
PYTHONPATH=code/py uv run python code/py/main.py run-integrated

# å®Ÿè¡Œè¨ˆç”»ç¢ºèª
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --show-plan

# å¼·åˆ¶å†å‡¦ç†
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --force-reprocess
```

### AIæ©Ÿèƒ½åˆ¶å¾¡
```bash
# AIæ©Ÿèƒ½ç„¡åŠ¹åŒ–
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --disable-ai-features

# ç‰¹å®šAIæ©Ÿèƒ½ã®ã¿ç„¡åŠ¹åŒ–
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --disable-tagger --disable-translate-abstract
```

### ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
```bash
# ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹å¤‰æ›´
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --workspace "/path/to/workspace"

# ç‰¹å®šè«–æ–‡ã®ã¿å‡¦ç†
PYTHONPATH=code/py uv run python code/py/main.py run-integrated --papers "paper1,paper2,paper3"
```