"""
AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ v4.0

çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç¬¬5æ®µéšŽã¨ã—ã¦ã€YAMLãƒ˜ãƒƒãƒ€ãƒ¼çµ±åˆæ©Ÿèƒ½ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import time
from typing import Dict, List, Optional, Tuple
from pathlib import Path

from .data_structures import AIGenerationResult, MappingStatistics
from .citation_mapping_engine import CitationMappingEngine
from ..shared.logger import get_integrated_logger


class AIMappingWorkflow:
    """AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    def __init__(self, config_manager=None, logger=None):
        """
        åˆæœŸåŒ–
        
        Args:
            config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        if logger:
            self.logger = logger.get_logger("AICitationSupport.AIMappingWorkflow")
        else:
            self.logger = get_integrated_logger().get_logger("AICitationSupport.AIMappingWorkflow")
        
        self.config_manager = config_manager
        
        # ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        self.mapping_engine = CitationMappingEngine(config_manager)
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±è¨ˆ
        self.execution_statistics = {
            'total_files_processed': 0,
            'successful_mappings': 0,
            'successful_generations': 0,
            'failed_operations': 0,
            'total_citations_processed': 0
        }
        
        self.logger.info("AIMappingWorkflow initialized successfully")
    
    def execute_ai_mapping(self, markdown_file: str, references_bib: str,
                          generate_ai_file: bool = False,
                          output_file: Optional[str] = None) -> AIGenerationResult:
        """
        AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã®å®Œå…¨å®Ÿè¡Œ
        
        Args:
            markdown_file: å¯¾è±¡Markdownãƒ•ã‚¡ã‚¤ãƒ«
            references_bib: å¯¾å¿œã™ã‚‹references.bibãƒ•ã‚¡ã‚¤ãƒ«
            generate_ai_file: AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ•ãƒ©ã‚°ï¼ˆä»•æ§˜æ›¸ã«å¾“ã„å¸¸ã«Falseï¼‰
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä½¿ç”¨ã•ã‚Œãªã„ï¼‰
            
        Returns:
            AIGenerationResult: å®Ÿè¡Œçµæžœ
            
        Process:
        1. è»½é‡å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
        2. YAMLãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"Starting AI mapping workflow for {markdown_file}")
            
            # å…¥åŠ›æ¤œè¨¼
            validation_result = self._validate_inputs(markdown_file, references_bib)
            if not validation_result[0]:
                return AIGenerationResult(
                    success=False,
                    error_message=validation_result[1]
                )
            
            # Step 1: è»½é‡å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
            self.logger.info("Step 1: Creating citation mapping...")
            citation_mapping = self.mapping_engine.create_citation_mapping(
                markdown_file, references_bib
            )
            
            if citation_mapping.total_citations == 0:
                self.logger.warning("No citations found - creating empty mapping")
            
            # Step 2: YAMLãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
            self.logger.info("Step 2: Updating YAML header...")
            update_success = self.mapping_engine.update_yaml_header(
                markdown_file, citation_mapping
            )
            
            if not update_success:
                return AIGenerationResult(
                    success=False,
                    error_message="Failed to update YAML header with citation mapping"
                )
            
            # çµ±è¨ˆæ›´æ–°
            self.execution_statistics['total_files_processed'] += 1
            self.execution_statistics['successful_mappings'] += 1
            self.execution_statistics['total_citations_processed'] += citation_mapping.total_citations
            
            # AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã¯å¸¸ã«ãƒžãƒƒãƒ”ãƒ³ã‚°ã®ã¿å®Ÿè¡Œ
            # ä»•æ§˜æ›¸ã«å¾“ã„ã€å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã¯è¡Œã„ã¾ã›ã‚“
            self.logger.info("AI mapping workflow completed (YAML header mapping only)")
            return AIGenerationResult(
                success=True,
                output_file="",  # AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç”Ÿæˆã—ãªã„
                statistics=MappingStatistics(
                    created_mappings=1,
                    total_citations_mapped=citation_mapping.total_citations,
                    processing_time=time.time() - start_time
                )
            )
            
        except Exception as e:
            self.execution_statistics['failed_operations'] += 1
            self.logger.error(f"AI mapping workflow failed: {e}")
            return AIGenerationResult(
                success=False,
                error_message=str(e)
            )
    
    def batch_execute_ai_mapping(self, file_pairs: List[Tuple[str, str]],
                                generate_ai_files: bool = False) -> Dict[str, AIGenerationResult]:
        """
        è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã‚’ãƒãƒƒãƒå®Ÿè¡Œ
        
        Args:
            file_pairs: (markdown_file, references_bib) ã®ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
            generate_ai_files: AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ•ãƒ©ã‚°ï¼ˆä»•æ§˜æ›¸ã«å¾“ã„å¸¸ã«Falseï¼‰
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«å â†’ AIGenerationResult ã®è¾žæ›¸
        """
        self.logger.info(f"Starting batch AI mapping for {len(file_pairs)} file pairs")
        
        results = {}
        successful_count = 0
        
        for i, (markdown_file, references_bib) in enumerate(file_pairs, 1):
            self.logger.info(f"Processing {i}/{len(file_pairs)}: {Path(markdown_file).name}")
            
            result = self.execute_ai_mapping(
                markdown_file, references_bib, generate_ai_file=False
            )
            
            results[markdown_file] = result
            
            if result.success:
                successful_count += 1
                self.logger.info(f"âœ… {Path(markdown_file).name} completed successfully")
            else:
                self.logger.error(f"âŒ {Path(markdown_file).name} failed: {result.error_message}")
        
        self.logger.info(f"Batch processing completed: {successful_count}/{len(file_pairs)} successful")
        return results
    
    def dry_run_ai_mapping(self, markdown_file: str, references_bib: str) -> str:
        """
        AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ
        
        Args:
            markdown_file: å¯¾è±¡Markdownãƒ•ã‚¡ã‚¤ãƒ«
            references_bib: å¯¾å¿œã™ã‚‹references.bibãƒ•ã‚¡ã‚¤ãƒ«
            
        Returns:
            ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³çµæžœãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            self.logger.info(f"Starting AI mapping dry run for {markdown_file}")
            
            # å…¥åŠ›æ¤œè¨¼
            validation_result = self._validate_inputs(markdown_file, references_bib)
            if not validation_result[0]:
                return f"âŒ Validation failed: {validation_result[1]}"
            
            # å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°åˆ†æžï¼ˆå®Ÿéš›ã®æ›´æ–°ã¯è¡Œã‚ãªã„ï¼‰
            citation_mapping = self.mapping_engine.create_citation_mapping(
                markdown_file, references_bib
            )
            
            # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            report_lines = [
                "ðŸ” AI Mapping Workflow Dry Run Analysis",
                "=" * 50,
                f"ðŸ“„ Markdown File: {Path(markdown_file).name}",
                f"ðŸ“š References File: {Path(references_bib).name}",
                f"ðŸ“Š Citations Found: {citation_mapping.total_citations}",
                f"ðŸ”— Mapping Version: {citation_mapping.mapping_version}",
                "",
                "ðŸ“‹ Citation Mapping Preview:",
                "-" * 30
            ]
            
            # ãƒžãƒƒãƒ”ãƒ³ã‚°è©³ç´°
            if citation_mapping.index_map:
                for number, key in sorted(citation_mapping.index_map.items()):
                    report_lines.append(f"  [{number}] â†’ {key}")
            else:
                report_lines.append("  No citations found")
            
            # å¼•ç”¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¿½åŠ 
            if citation_mapping.index_map:
                citation_preview_lines = []
                for number, citation_info in sorted(citation_mapping.index_map.items()):
                    citation_preview_lines.append(f"  [{number}] {citation_info.title} ({citation_info.year})")
                
                report_lines.extend([
                    "",
                    "ðŸ“š Citation Preview:",
                    "-" * 20,
                    *citation_preview_lines
                ])
            
            report_lines.extend([
                "",
                "âœ… Dry run completed successfully"
            ])
            
            return "\n".join(report_lines)
            
        except Exception as e:
            self.logger.error(f"Dry run failed: {e}")
            return f"âŒ Dry run failed: {e}"
    
    def _validate_inputs(self, markdown_file: str, references_bib: str) -> Tuple[bool, str]:
        """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
        markdown_path = Path(markdown_file)
        bib_path = Path(references_bib)
        
        if not markdown_path.exists():
            return False, f"Markdown file not found: {markdown_file}"
        
        if not bib_path.exists():
            return False, f"References file not found: {references_bib}"
        
        if not markdown_path.suffix.lower() in ['.md', '.markdown']:
            return False, f"Invalid markdown file extension: {markdown_path.suffix}"
        
        if not bib_path.suffix.lower() == '.bib':
            return False, f"Invalid BibTeX file extension: {bib_path.suffix}"
        
        return True, "Validation passed"
    
    def get_workflow_statistics(self) -> Dict[str, any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—"""
        stats = self.execution_statistics.copy()
        
        # æˆåŠŸçŽ‡ã‚’è¿½åŠ 
        total_processed = stats['total_files_processed']
        if total_processed > 0:
            stats['mapping_success_rate'] = stats['successful_mappings'] / total_processed
            stats['generation_success_rate'] = stats['successful_generations'] / total_processed
        else:
            stats['mapping_success_rate'] = 0.0
            stats['generation_success_rate'] = 0.0
        
        return stats
    
    def reset_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.execution_statistics = {
            'total_files_processed': 0,
            'successful_mappings': 0,
            'successful_generations': 0,
            'failed_operations': 0,
            'total_citations_processed': 0
        }
        self.logger.info("Workflow statistics reset") 