"""
AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ v4.0

çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç¬¬5æ®µéšŽã¨ã—ã¦ã€AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ©Ÿèƒ½ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import time
from typing import Dict, List, Optional, Tuple
from pathlib import Path

from .data_structures import AIGenerationResult, MappingStatistics
from .citation_mapping_engine import CitationMappingEngine
from .ai_assistant_file_generator import AIAssistantFileGenerator
from ..shared.logger import get_integrated_logger


class AIMappingWorkflow:
    """AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    def __init__(self, config_manager=None, logger=None):
        """
        åˆæœŸåŒ–
        
        Args:
            config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        if logger:
            self.logger = logger.get_logger("AICitationSupport.AIMappingWorkflow")
        else:
            self.logger = get_integrated_logger().get_logger("AICitationSupport.AIMappingWorkflow")
        
        self.config_manager = config_manager
        
        # ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        self.mapping_engine = CitationMappingEngine(config_manager)
        self.file_generator = AIAssistantFileGenerator(config_manager)
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±è¨ˆ
        self.execution_statistics = {
            'total_files_processed': 0,
            'successful_mappings': 0,
            'successful_generations': 0,
            'failed_operations': 0,
            'total_citations_processed': 0
        }
        
        self.logger.info("AIMappingWorkflow initialized successfully")
    
    def execute_ai_mapping(self, markdown_file: str, references_bib: str,
                          generate_ai_file: bool = True,
                          output_file: Optional[str] = None) -> AIGenerationResult:
        """
        AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã®å®Œå…¨å®Ÿè¡Œ
        
        Args:
            markdown_file: å¯¾è±¡Markdownãƒ•ã‚¡ã‚¤ãƒ«
            references_bib: å¯¾å¿œã™ã‚‹references.bibãƒ•ã‚¡ã‚¤ãƒ«
            generate_ai_file: AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ•ãƒ©ã‚°
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            AIGenerationResult: å®Ÿè¡Œçµæžœ
            
        Process:
        1. è»½é‡å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
        2. YAMLãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
        3. AIç”¨çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        4. å“è³ªæ¤œè¨¼
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"Starting AI mapping workflow for {markdown_file}")
            
            # å…¥åŠ›æ¤œè¨¼
            validation_result = self._validate_inputs(markdown_file, references_bib)
            if not validation_result[0]:
                return AIGenerationResult(
                    success=False,
                    error_message=validation_result[1]
                )
            
            # Step 1: è»½é‡å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
            self.logger.info("Step 1: Creating citation mapping...")
            citation_mapping = self.mapping_engine.create_citation_mapping(
                markdown_file, references_bib
            )
            
            if citation_mapping.total_citations == 0:
                self.logger.warning("No citations found - creating empty mapping")
            
            # Step 2: YAMLãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
            self.logger.info("Step 2: Updating YAML header...")
            update_success = self.mapping_engine.update_yaml_header(
                markdown_file, citation_mapping
            )
            
            if not update_success:
                return AIGenerationResult(
                    success=False,
                    error_message="Failed to update YAML header with citation mapping"
                )
            
            # çµ±è¨ˆæ›´æ–°
            self.execution_statistics['total_files_processed'] += 1
            self.execution_statistics['successful_mappings'] += 1
            self.execution_statistics['total_citations_processed'] += citation_mapping.total_citations
            
            # Step 3: AIç”¨çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if generate_ai_file:
                self.logger.info("Step 3: Generating AI readable file...")
                generation_result = self.file_generator.generate_ai_readable_file(
                    markdown_file, output_file
                )
                
                if generation_result.success:
                    self.execution_statistics['successful_generations'] += 1
                    
                    # Step 4: å“è³ªæ¤œè¨¼
                    self.logger.info("Step 4: Validating AI file quality...")
                    quality_ok, issues = self.file_generator.validate_ai_file_quality(
                        generation_result.output_file
                    )
                    
                    if not quality_ok:
                        generation_result.warnings.extend(issues)
                        self.logger.warning(f"Quality issues found: {issues}")
                    
                    # å®Ÿè¡Œæ™‚é–“ã‚’è¿½åŠ 
                    if generation_result.statistics:
                        generation_result.statistics.processing_time = time.time() - start_time
                    
                    self.logger.info(f"AI mapping workflow completed successfully in {time.time() - start_time:.2f}s")
                    return generation_result
                else:
                    self.execution_statistics['failed_operations'] += 1
                    return generation_result
            else:
                # ãƒžãƒƒãƒ”ãƒ³ã‚°ã®ã¿å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ
                self.logger.info("AI mapping workflow completed (mapping only)")
                return AIGenerationResult(
                    success=True,
                    output_file="",  # AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç”Ÿæˆã—ã¦ã„ãªã„
                    statistics=MappingStatistics(
                        created_mappings=1,
                        total_citations_mapped=citation_mapping.total_citations,
                        processing_time=time.time() - start_time
                    )
                )
            
        except Exception as e:
            self.execution_statistics['failed_operations'] += 1
            self.logger.error(f"AI mapping workflow failed: {e}")
            return AIGenerationResult(
                success=False,
                error_message=str(e)
            )
    
    def batch_execute_ai_mapping(self, file_pairs: List[Tuple[str, str]],
                                generate_ai_files: bool = True) -> Dict[str, AIGenerationResult]:
        """
        è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã‚’ãƒãƒƒãƒå®Ÿè¡Œ
        
        Args:
            file_pairs: (markdown_file, references_bib) ã®ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
            generate_ai_files: AIç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ•ãƒ©ã‚°
            
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«å â†’ AIGenerationResult ã®è¾žæ›¸
        """
        self.logger.info(f"Starting batch AI mapping for {len(file_pairs)} file pairs")
        
        results = {}
        successful_count = 0
        
        for i, (markdown_file, references_bib) in enumerate(file_pairs, 1):
            self.logger.info(f"Processing {i}/{len(file_pairs)}: {Path(markdown_file).name}")
            
            result = self.execute_ai_mapping(
                markdown_file, references_bib, generate_ai_files
            )
            
            results[markdown_file] = result
            
            if result.success:
                successful_count += 1
                self.logger.info(f"âœ… {Path(markdown_file).name} completed successfully")
            else:
                self.logger.error(f"âŒ {Path(markdown_file).name} failed: {result.error_message}")
        
        self.logger.info(f"Batch processing completed: {successful_count}/{len(file_pairs)} successful")
        return results
    
    def dry_run_ai_mapping(self, markdown_file: str, references_bib: str) -> str:
        """
        AIç†è§£æ”¯æ´å¼•ç”¨æ–‡çŒ®çµ±åˆã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ
        
        Args:
            markdown_file: å¯¾è±¡Markdownãƒ•ã‚¡ã‚¤ãƒ«
            references_bib: å¯¾å¿œã™ã‚‹references.bibãƒ•ã‚¡ã‚¤ãƒ«
            
        Returns:
            ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³çµæžœãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            self.logger.info(f"Starting AI mapping dry run for {markdown_file}")
            
            # å…¥åŠ›æ¤œè¨¼
            validation_result = self._validate_inputs(markdown_file, references_bib)
            if not validation_result[0]:
                return f"âŒ Validation failed: {validation_result[1]}"
            
            # å¼•ç”¨ãƒžãƒƒãƒ”ãƒ³ã‚°åˆ†æžï¼ˆå®Ÿéš›ã®æ›´æ–°ã¯è¡Œã‚ãªã„ï¼‰
            citation_mapping = self.mapping_engine.create_citation_mapping(
                markdown_file, references_bib
            )
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
            preview = self.file_generator.generate_citation_preview(markdown_file, max_citations=5)
            
            # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            report_lines = [
                "ðŸ” AI Mapping Workflow Dry Run Analysis",
                "=" * 50,
                f"ðŸ“„ Markdown File: {Path(markdown_file).name}",
                f"ðŸ“š References File: {Path(references_bib).name}",
                f"ðŸ“Š Citations Found: {citation_mapping.total_citations}",
                f"ðŸ”— Mapping Version: {citation_mapping.mapping_version}",
                "",
                "ðŸ“‹ Citation Mapping Preview:",
                "-" * 30
            ]
            
            # ãƒžãƒƒãƒ”ãƒ³ã‚°è©³ç´°
            if citation_mapping.index_map:
                for number, key in sorted(citation_mapping.index_map.items()):
                    report_lines.append(f"  [{number}] â†’ {key}")
            else:
                report_lines.append("  No citations found")
            
            report_lines.extend([
                "",
                "ðŸ“š Citation Preview:",
                "-" * 20,
                preview,
                "",
                "âœ… Dry run completed successfully"
            ])
            
            return "\n".join(report_lines)
            
        except Exception as e:
            self.logger.error(f"Dry run failed: {e}")
            return f"âŒ Dry run failed: {e}"
    
    def _validate_inputs(self, markdown_file: str, references_bib: str) -> Tuple[bool, str]:
        """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
        markdown_path = Path(markdown_file)
        bib_path = Path(references_bib)
        
        if not markdown_path.exists():
            return False, f"Markdown file not found: {markdown_file}"
        
        if not bib_path.exists():
            return False, f"References file not found: {references_bib}"
        
        if not markdown_path.suffix.lower() in ['.md', '.markdown']:
            return False, f"Invalid markdown file extension: {markdown_path.suffix}"
        
        if not bib_path.suffix.lower() == '.bib':
            return False, f"Invalid BibTeX file extension: {bib_path.suffix}"
        
        return True, "Validation passed"
    
    def get_workflow_statistics(self) -> Dict[str, any]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—"""
        stats = self.execution_statistics.copy()
        
        # æˆåŠŸçŽ‡ã‚’è¿½åŠ 
        total_processed = stats['total_files_processed']
        if total_processed > 0:
            stats['mapping_success_rate'] = stats['successful_mappings'] / total_processed
            stats['generation_success_rate'] = stats['successful_generations'] / total_processed
        else:
            stats['mapping_success_rate'] = 0.0
            stats['generation_success_rate'] = 0.0
        
        return stats
    
    def reset_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.execution_statistics = {
            'total_files_processed': 0,
            'successful_mappings': 0,
            'successful_generations': 0,
            'failed_operations': 0,
            'total_citations_processed': 0
        }
        self.logger.info("Workflow statistics reset") 