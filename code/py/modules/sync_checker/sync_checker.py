#!/usr/bin/env python3
"""
ObsClippingsManager v3.2.0 - SyncChecker

BibTeX â†” Clippingsé–“ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
organizeå‡¦ç†å®Œäº†å¾Œã®å®Ÿè¡Œã‚’æƒ³å®š
"""

import os
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆrelative importå¯¾å¿œï¼‰
try:
    from ..shared_modules.config_manager import ConfigManager
    from ..shared_modules.integrated_logger import IntegratedLogger
    from ..shared_modules.bibtex_parser import BibTeXParser
    from ..status_management_yaml.yaml_header_processor import YAMLHeaderProcessor
    from ..shared_modules.exceptions import (
        ObsClippingsManagerError,
        ValidationError,
        FileSystemError,
        ProcessingError
    )
    from ..shared_modules.file_utils import FileUtils
except ImportError:
    # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import sys
    import os
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
    
    from code.py.modules.shared_modules.config_manager import ConfigManager
    from code.py.modules.shared_modules.integrated_logger import IntegratedLogger
    from code.py.modules.shared_modules.bibtex_parser import BibTeXParser
    from code.py.modules.status_management_yaml.yaml_header_processor import YAMLHeaderProcessor
    from code.py.modules.shared_modules.exceptions import (
        ObsClippingsManagerError,
        ValidationError,
        FileSystemError,
        ProcessingError
    )
    from code.py.modules.shared_modules.file_utils import FileUtils


class SyncChecker:
    """
    BibTeX â†” Clippingsé–“ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹
    
    è²¬å‹™:
    - BibTeXæ–‡çŒ®ã¨Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«é–“ã®æ•´åˆæ€§æ¤œè¨¼
    - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¸€è‡´ç¢ºèªï¼ˆDOIã€ã‚¿ã‚¤ãƒˆãƒ«ã€è‘—è€…ãªã©ï¼‰
    - è»½å¾®ãªä¸æ•´åˆã®è‡ªå‹•ä¿®æ­£
    - æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    - YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã®syncçŠ¶æ…‹æ›´æ–°
    """
    
    def __init__(self, config_manager: ConfigManager, logger: IntegratedLogger):
        """
        SyncCheckerã®åˆæœŸåŒ–
        
        Args:
            config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            logger: ãƒ­ã‚°ç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.config_manager = config_manager
        self.logger = logger.get_logger('SyncChecker')
        
        # ä¾å­˜ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        self.bibtex_parser = BibTeXParser(logger.get_logger('BibTeXParser'))
        self.yaml_processor = YAMLHeaderProcessor(config_manager, logger)
        self.file_utils = FileUtils()
        
        # syncè¨­å®šã®å–å¾—ï¼ˆConfigManagerã®å…¨è¨­å®šã‹ã‚‰å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
        full_config = self.config_manager.get_config()
        self.sync_config = full_config.get('sync_checker', {
            'enabled': True,
            'auto_fix_minor_issues': True,
            'backup_before_auto_fix': True,
            'retry_attempts': 3
        })
        
        self.logger.info("SyncChecker initialized successfully")
    
    def check_workspace_consistency(
        self, 
        workspace_path: str, 
        bibtex_file: str, 
        clippings_dir: str
    ) -> Dict[str, Any]:
        """
        ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹å…¨ä½“ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        
        Args:
            workspace_path: ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ãƒ‘ã‚¹
            bibtex_file: BibTeXãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            clippings_dir: Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        
        Returns:
            Dict[str, Any]: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ
        """
        self.logger.info(f"Starting workspace consistency check: {workspace_path}")
        
        try:
            # BibTeXãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ
            bibtex_entries = self._parse_bibtex_file(bibtex_file)
            self.logger.info(f"Found {len(bibtex_entries)} BibTeX entries")
            
            # Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            markdown_files = self._find_markdown_files(clippings_dir)
            self.logger.info(f"Found {len(markdown_files)} organized markdown files")
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            consistency_results = self._perform_consistency_checks(
                bibtex_entries, markdown_files, clippings_dir
            )
            
            # çµæœã‚µãƒãƒªãƒ¼ä½œæˆ
            result = self._create_consistency_summary(consistency_results)
            result['workspace_path'] = workspace_path
            result['bibtex_file'] = bibtex_file
            result['clippings_dir'] = clippings_dir
            result['checked_at'] = datetime.now().isoformat()
            
            # YAMLãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
            self._update_sync_status_in_yaml_headers(
                consistency_results['papers_checked'], result
            )
            
            self.logger.info(f"Workspace consistency check completed: {result['consistency_status']}")
            return result
            
        except Exception as e:
            error_msg = f"Workspace consistency check failed: {str(e)}"
            self.logger.error(error_msg)
            raise ProcessingError(error_msg, cause=e)
    
    def check_paper_consistency(
        self, 
        citation_key: str, 
        paper_dir: str, 
        bibtex_entry: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å€‹åˆ¥è«–æ–‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        
        Args:
            citation_key: å¼•ç”¨ã‚­ãƒ¼
            paper_dir: è«–æ–‡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
            bibtex_entry: BibTeXã‚¨ãƒ³ãƒˆãƒªãƒ¼è¾æ›¸
        
        Returns:
            Dict[str, Any]: å€‹åˆ¥è«–æ–‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ
        """
        self.logger.debug(f"Checking paper consistency: {citation_key}")
        
        try:
            paper_path = Path(paper_dir)
            markdown_file = paper_path / f"{citation_key}.md"
            
            if not markdown_file.exists():
                return {
                    'citation_key': citation_key,
                    'consistency_status': 'missing_markdown',
                    'markdown_file_exists': False,
                    'issues': ['Markdown file not found']
                }
            
            # YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã®è§£æ
            yaml_data, _ = self.yaml_processor.parse_yaml_header(markdown_file)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ
            metadata_mismatches = self._compare_metadata(yaml_data, bibtex_entry)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åãƒã‚§ãƒƒã‚¯
            filename_issues = self._check_filename_consistency(
                citation_key, markdown_file, paper_path
            )
            
            # çµæœæ§‹ç¯‰
            issues = metadata_mismatches + filename_issues
            consistency_status = 'validated' if len(issues) == 0 else 'inconsistent'
            
            result = {
                'citation_key': citation_key,
                'consistency_status': consistency_status,
                'markdown_file_exists': True,
                'markdown_file_path': str(markdown_file),
                'metadata_mismatches': metadata_mismatches,
                'filename_issues': filename_issues,
                'issues': issues,
                'checked_at': datetime.now().isoformat()
            }
            
            self.logger.debug(f"Paper consistency check completed: {citation_key} - {consistency_status}")
            return result
            
        except Exception as e:
            error_msg = f"Paper consistency check failed for {citation_key}: {str(e)}"
            self.logger.error(error_msg)
            raise ProcessingError(error_msg, cause=e)
    
    def auto_fix_minor_inconsistencies(self, check_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        è»½å¾®ãªä¸æ•´åˆã®è‡ªå‹•ä¿®æ­£
        
        Args:
            check_results: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ
        
        Returns:
            Dict[str, Any]: è‡ªå‹•ä¿®æ­£çµæœ
        """
        if not self.sync_config.get('auto_fix_minor_issues', False):
            self.logger.info("Auto-fix is disabled in configuration")
            return {
                'auto_fix_enabled': False,
                'corrections_applied': [],
                'auto_fix_successful': True
            }
        
        self.logger.info("Starting auto-fix for minor inconsistencies")
        corrections_applied = []
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            if self.sync_config.get('backup_before_auto_fix', True):
                self._create_backup_before_auto_fix(check_results)
            
            # è»½å¾®ãªå•é¡Œã®è‡ªå‹•ä¿®æ­£å‡¦ç†
            if 'minor_issues' in check_results:
                for issue in check_results['minor_issues']:
                    correction = self._apply_auto_fix(issue)
                    if correction:
                        corrections_applied.append(correction)
            
            result = {
                'auto_fix_enabled': True,
                'corrections_applied': corrections_applied,
                'auto_fix_successful': True,
                'fixed_at': datetime.now().isoformat()
            }
            
            self.logger.info(f"Auto-fix completed: {len(corrections_applied)} corrections applied")
            return result
            
        except Exception as e:
            error_msg = f"Auto-fix failed: {str(e)}"
            self.logger.error(error_msg)
            return {
                'auto_fix_enabled': True,
                'corrections_applied': corrections_applied,
                'auto_fix_successful': False,
                'error': error_msg
            }
    
    def _parse_bibtex_file(self, bibtex_file: str) -> Dict[str, Dict[str, Any]]:
        """BibTeXãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æ"""
        try:
            bibtex_path = Path(bibtex_file)
            if not bibtex_path.exists():
                raise FileSystemError(f"BibTeX file not found: {bibtex_file}")
            
            # BibTeXParserã‚’ä½¿ç”¨ã—ã¦è§£æ
            parsed_entries = self.bibtex_parser.parse_file(bibtex_file)
            
            # BibTeXParserã¯æ—¢ã«citation_keyã‚’ã‚­ãƒ¼ã¨ã—ãŸè¾æ›¸ã‚’è¿”ã™ãŸã‚ã€ãã®ã¾ã¾ä½¿ç”¨
            return parsed_entries
            
        except Exception as e:
            raise ProcessingError(f"Failed to parse BibTeX file: {bibtex_file}", cause=e)
    
    def _find_markdown_files(self, clippings_dir: str) -> Dict[str, str]:
        """Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        try:
            clippings_path = Path(clippings_dir)
            markdown_files = {}
            
            # 1. organizeæ¸ˆã¿ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’æ¤œç´¢ï¼ˆcitation_key/citation_key.mdï¼‰
            for paper_dir in clippings_path.iterdir():
                if paper_dir.is_dir():
                    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                    md_files = list(paper_dir.glob("*.md"))
                    if md_files:
                        md_file = md_files[0]  # æœ€åˆã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                        
                        try:
                            # YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰citation_keyã‚’èª­ã¿å–ã‚Š
                            yaml_data, _ = self.yaml_processor.parse_yaml_header(md_file)
                            citation_key = yaml_data.get('citation_key')
                            
                            if citation_key:
                                # å®Ÿéš›ã®citation_keyã‚’ä½¿ç”¨
                                markdown_files[citation_key] = str(md_file)
                                self.logger.debug(f"Found organized markdown with citation_key: {citation_key} at {md_file}")
                            else:
                                # citation_keyãŒãªã„å ´åˆã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                                dir_name = paper_dir.name
                                markdown_files[dir_name] = str(md_file)
                                self.logger.warning(f"No citation_key in YAML header, using directory name: {dir_name}")
                        except Exception as e:
                            # YAMLãƒ˜ãƒƒãƒ€ãƒ¼è§£æã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ä½¿ç”¨
                            dir_name = paper_dir.name
                            markdown_files[dir_name] = str(md_file)
                            self.logger.warning(f"Failed to parse YAML header for {md_file}, using directory name: {dir_name}")
            
            # 2. Clippingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã®å­¤ç«‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            for md_file in clippings_path.glob("*.md"):
                if md_file.is_file():
                    try:
                        # YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰citation_keyã‚’èª­ã¿å–ã‚Š
                        yaml_data, _ = self.yaml_processor.parse_yaml_header(md_file)
                        citation_key = yaml_data.get('citation_key')
                        
                        if citation_key:
                            # citation_keyãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                            markdown_files[citation_key] = str(md_file)
                            self.logger.debug(f"Found orphaned markdown with citation_key: {citation_key} at {md_file}")
                        else:
                            # citation_keyãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’ä½¿ç”¨
                            file_stem = md_file.stem
                            markdown_files[file_stem] = str(md_file)
                            self.logger.warning(f"Found orphaned markdown without citation_key, using filename: {file_stem}")
                    except Exception as e:
                        # YAMLãƒ˜ãƒƒãƒ€ãƒ¼è§£æã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
                        file_stem = md_file.stem
                        markdown_files[file_stem] = str(md_file)
                        self.logger.warning(f"Failed to parse YAML header for orphaned file {md_file}, using filename: {file_stem}")
            
            self.logger.info(f"Found {len(markdown_files)} total markdown files in {clippings_dir}")
            return markdown_files
            
        except Exception as e:
            raise ProcessingError(f"Failed to find markdown files in: {clippings_dir}", cause=e)
    
    def _perform_consistency_checks(
        self, 
        bibtex_entries: Dict[str, Dict[str, Any]], 
        markdown_files: Dict[str, str], 
        clippings_dir: str
    ) -> Dict[str, Any]:
        """æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
        papers_checked = []
        missing_markdown = []
        orphaned_markdown = []
        issues_detected = 0
        
        # BibTeXã‚¨ãƒ³ãƒˆãƒªãƒ¼ã«å¯¾å¿œã™ã‚‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        for citation_key, bibtex_entry in bibtex_entries.items():
            if citation_key in markdown_files:
                # å€‹åˆ¥è«–æ–‡ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                paper_dir = Path(markdown_files[citation_key]).parent
                paper_result = self.check_paper_consistency(
                    citation_key, str(paper_dir), bibtex_entry
                )
                papers_checked.append(paper_result)
                
                if paper_result['consistency_status'] != 'validated':
                    issues_detected += len(paper_result['issues'])
            else:
                # Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„
                missing_markdown.append({
                    'citation_key': citation_key,
                    'bibtex_entry': bibtex_entry
                })
                issues_detected += 1
        
        # å­¤ç«‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        for citation_key, markdown_file in markdown_files.items():
            if citation_key not in bibtex_entries:
                orphaned_markdown.append({
                    'citation_key': citation_key,
                    'markdown_file': markdown_file
                })
                issues_detected += 1
        
        return {
            'papers_checked': papers_checked,
            'missing_markdown_files': missing_markdown,
            'orphaned_markdown_files': orphaned_markdown,
            'issues_detected': issues_detected
        }
    
    def _compare_metadata(
        self, 
        yaml_data: Dict[str, Any], 
        bibtex_entry: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ"""
        mismatches = []
        
        # DOIæ¯”è¼ƒ
        yaml_doi = yaml_data.get('doi', '').strip()
        bibtex_doi = bibtex_entry.get('doi', '').strip()
        
        if yaml_doi and bibtex_doi and yaml_doi != bibtex_doi:
            mismatches.append({
                'field': 'doi',
                'yaml_value': yaml_doi,
                'bibtex_value': bibtex_doi,
                'severity': 'major'
            })
        
        # ã‚¿ã‚¤ãƒˆãƒ«æ¯”è¼ƒï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã®é•ã„ã¯è»½å¾®ã¨ã™ã‚‹ï¼‰
        yaml_title = yaml_data.get('title', '').strip()
        bibtex_title = bibtex_entry.get('title', '').strip()
        
        if yaml_title and bibtex_title:
            if yaml_title.lower() != bibtex_title.lower():
                severity = 'minor' if yaml_title.lower().replace(' ', '') == bibtex_title.lower().replace(' ', '') else 'major'
                mismatches.append({
                    'field': 'title',
                    'yaml_value': yaml_title,
                    'bibtex_value': bibtex_title,
                    'severity': severity
                })
        
        return mismatches
    
    def _check_filename_consistency(
        self, 
        citation_key: str, 
        markdown_file: Path, 
        paper_dir: Path
    ) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        expected_filename = f"{citation_key}.md"
        actual_filename = markdown_file.name
        
        if actual_filename != expected_filename:
            issues.append({
                'type': 'filename_normalization',
                'current_filename': actual_filename,
                'expected_filename': expected_filename,
                'severity': 'minor'
            })
        
        return issues
    
    def _create_consistency_summary(self, consistency_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœã®ã‚µãƒãƒªãƒ¼ä½œæˆ"""
        total_papers = len(consistency_results['papers_checked'])
        validated_papers = sum(
            1 for paper in consistency_results['papers_checked'] 
            if paper['consistency_status'] == 'validated'
        )
        
        consistency_status = 'validated' if consistency_results['issues_detected'] == 0 else 'issues_detected'
        
        return {
            'consistency_status': consistency_status,
            'issues_detected': consistency_results['issues_detected'],
            'papers_checked': total_papers,
            'validated_papers': validated_papers,
            'missing_markdown_files': consistency_results['missing_markdown_files'],
            'orphaned_markdown_files': consistency_results['orphaned_markdown_files'],
            'detailed_results': consistency_results['papers_checked']
        }
    
    def _update_sync_status_in_yaml_headers(
        self, 
        papers_checked: List[Dict[str, Any]], 
        overall_result: Dict[str, Any]
    ) -> None:
        """YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã®syncçŠ¶æ…‹æ›´æ–°"""
        for paper_result in papers_checked:
            if paper_result.get('markdown_file_exists', False):
                try:
                    markdown_file = paper_result['markdown_file_path']
                    
                    # ç¾åœ¨ã®YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—
                    yaml_data, content = self.yaml_processor.parse_yaml_header(Path(markdown_file))
                    
                    # sync_metadataã®è¿½åŠ /æ›´æ–°
                    yaml_data['sync_metadata'] = {
                        'checked_at': paper_result['checked_at'],
                        'consistency_status': paper_result['consistency_status'],
                        'issues_detected': len(paper_result['issues']),
                        'auto_corrections_applied': 0,  # å®Ÿéš›ã®ä¿®æ­£å¾Œã«æ›´æ–°
                        'corrections_applied': []
                    }
                    
                    # processing_statusã®æ›´æ–°
                    if 'processing_status' not in yaml_data:
                        yaml_data['processing_status'] = {}
                    
                    yaml_data['processing_status']['sync'] = (
                        'completed' if paper_result['consistency_status'] == 'validated' 
                        else 'failed'
                    )
                    
                    # YAMLãƒ˜ãƒƒãƒ€ãƒ¼ã®æ›¸ãæˆ»ã—
                    self.yaml_processor.write_yaml_header(Path(markdown_file), yaml_data, content)
                    
                except Exception as e:
                    self.logger.error(f"Failed to update YAML header for {paper_result['citation_key']}: {str(e)}")
    
    def _create_backup_before_auto_fix(self, check_results: Dict[str, Any]) -> None:
        """è‡ªå‹•ä¿®æ­£å‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.logger.info("Creating backup before auto-fix (placeholder)")
    
    def _apply_auto_fix(self, issue: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å€‹åˆ¥å•é¡Œã®è‡ªå‹•ä¿®æ­£é©ç”¨"""
        try:
            if issue.get('type') == 'filename_normalization':
                # ãƒ•ã‚¡ã‚¤ãƒ«åæ­£è¦åŒ–ã®è‡ªå‹•ä¿®æ­£ï¼ˆå®Ÿè£…ä¾‹ï¼‰
                self.logger.info(f"Auto-fixing filename normalization for {issue.get('citation_key')}")
                return {
                    'type': 'filename_normalization',
                    'description': 'Filename normalized to match citation_key',
                    'timestamp': datetime.now().isoformat(),
                    'citation_key': issue.get('citation_key')
                }
            
            return None
            
        except Exception as e:
            self.logger.error(f"Auto-fix failed for issue {issue}: {str(e)}")
            return None
    
    def display_doi_links(self, missing_papers, orphaned_papers):
        """
        ä¸è¶³ãƒ»å­¤ç«‹è«–æ–‡ã®DOIãƒªãƒ³ã‚¯è¡¨ç¤º
        
        Args:
            missing_papers: BibTeXã«ã‚ã‚‹ãŒMarkdownãŒãªã„è«–æ–‡ãƒªã‚¹ãƒˆ
            orphaned_papers: Markdownã«ã‚ã‚‹ãŒBibTeXã«ãªã„è«–æ–‡ãƒªã‚¹ãƒˆ
        """
        if not self.sync_config.get('display_doi_links', True):
            return
        
        doi_link_format = self.sync_config.get('doi_link_format', 'https://doi.org/{doi}')
        
        # ä¸è¶³Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if missing_papers:
            print(f"\nğŸ“‹ ä¸è¶³Markdownãƒ•ã‚¡ã‚¤ãƒ« ({len(missing_papers)}ä»¶):")
            for paper in missing_papers:
                citation_key = paper.get('citation_key', 'Unknown')
                bibtex_entry = paper.get('bibtex_entry', {})
                doi = bibtex_entry.get('doi', '')
                
                print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                print(f"â”‚ Citation Key: {citation_key:<63} â”‚")
                if doi:
                    doi_link = doi_link_format.format(doi=doi)
                    print(f"â”‚ DOI Link: {doi_link:<67} â”‚")
                else:
                    print(f"â”‚ DOI Link: DOIæƒ…å ±ãªã—{'':<59} â”‚")
                print(f"â”‚ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„{'':<34} â”‚")
                print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        # å­¤ç«‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if orphaned_papers:
            print(f"\nğŸ”— å­¤ç«‹Markdownãƒ•ã‚¡ã‚¤ãƒ« ({len(orphaned_papers)}ä»¶):")
            for paper in orphaned_papers:
                citation_key = paper.get('citation_key', 'Unknown')
                markdown_file = paper.get('markdown_file', '')
                
                # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰DOIæƒ…å ±ã‚’å–å¾—
                doi = self._extract_doi_from_markdown(markdown_file)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é©åˆ‡ãªé•·ã•ã«åˆ‡ã‚Šè©°ã‚
                file_name = Path(markdown_file).name if markdown_file else 'Unknown'
                if len(file_name) > 63:
                    file_name = file_name[:60] + "..."
                
                print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                print(f"â”‚ File: {file_name:<71} â”‚")
                if doi:
                    doi_link = doi_link_format.format(doi=doi)
                    print(f"â”‚ DOI Link: {doi_link:<67} â”‚")
                else:
                    print(f"â”‚ DOI Link: DOIæƒ…å ±ãªã—{'':<59} â”‚")
                print(f"â”‚ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: BibTeXã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ã—ã¦ãã ã•ã„{'':<31} â”‚")
                print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    def _extract_doi_from_markdown(self, markdown_file: str) -> str:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰DOIæƒ…å ±ã‚’æŠ½å‡º"""
        try:
            if not markdown_file or not Path(markdown_file).exists():
                return ''
            
            yaml_data, _ = self.yaml_processor.parse_yaml_header(Path(markdown_file))
            return yaml_data.get('doi', '')
            
        except Exception as e:
            self.logger.debug(f"Failed to extract DOI from {markdown_file}: {str(e)}")
            return '' 